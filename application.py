import numpy as np
import json
from flask import Flask, request, render_template, jsonify
import requests
from database import load_embeddings_from_db
from config import OPENAI_API_KEY, EMBEDDING_MODEL, OPENAI_EMBEDDING_URL, LLM_API_URL
import re

app = Flask(__name__)


# --- Pomocn칠 funkce ---

def get_query_embedding(query):
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    data = {"input": query, "model": EMBEDDING_MODEL}
    response = requests.post(OPENAI_EMBEDDING_URL, headers=headers, json=data)
    if response.status_code == 200:
        return np.array(response.json()["data"][0]["embedding"])
    return None


def cosine_similarity(v1, v2):
    norm_v1 = np.linalg.norm(v1)
    norm_v2 = np.linalg.norm(v2)
    if norm_v1 == 0 or norm_v2 == 0:
        return 0
    return np.dot(v1, v2) / (norm_v1 * norm_v2)


def is_subject_code(word):
    """
    Rozpozn치, zda slovo vypad치 jako k칩d p콏edm캩tu (nap콏. ALG1, OA1, KP/ALG).
    Vylou캜칤 b캩쬹치 slova jako 'kontakt', 'katedra', 'na'.
    """
    # Mus칤 m칤t 2-8 znak콢
    if not (2 <= len(word) <= 8):
        return False

    # Mus칤 obsahovat alespo켿 jedno velk칠 p칤smeno nebo 캜칤slo (pokud je zad치no velk칳mi)
    # Ale my dostaneme 'word' u z tokenizace, tak쬰 mus칤me b칳t opatrn칤.

    # Seznam zak치zan칳ch slov (b캩쬹치 slova, kter치 by se mohla spl칠st s k칩dy)
    stopwords = {'pro', 'kde', 'kdy', 'jak', 'co', 'na', 'do', 'se', 'ze', 'ke', 've',
                 'test', 'info', 'data', 'stag', 'fim', 'uhk', 'pan', 'pani',
                 'doc', 'prof', 'ing', 'mgr', 'bc', 'phd', 'kontakt', 'vedouci'}

    if word.lower() in stopwords:
        return False

    # Mus칤 obsahovat alespo켿 jedno p칤smeno (ne jen 캜칤sla, i kdy na FIMu jsou i k칩dy s 캜칤sly)
    # Ale hlavn캩: K칩dy b칳vaj칤 'OA1', 'ALG', '4IT101'.
    # Pokud je to jen "Dominik", tak to projde jako validn칤 slovo, ale my chceme jen K칍DY.

    # Zkus칤me p콏칤sn캩j코칤 pravidlo:
    # 1. Obsahuje 캜칤slo? (OA1, 4IT) -> JASN칗 K칍D
    if any(char.isdigit() for char in word):
        return True

    # 2. Je to cel칠 velk칳mi p칤smeny a m치 to 2-5 znak콢? (ALG, ZPRO) -> ASI K칍D
    # (Tady spol칠h치me na to, 쬰 u쬴vatel nap칤코e ALG, ne alg. Pokud nap칤코e alg, boostneme to taky, nevad칤).
    if word.isalpha() and len(word) <= 5:
        return True

    return False


def find_top_k_matches(query_embedding, embeddings, query_text, k=3):
    """Najde K nejlep코칤ch shod s CHYTR칗M boostem pro k칩dy."""
    if not embeddings:
        return []

    # Rozbijeme dotaz na slova. Zachov치me p콢vodn칤 velikost p칤smen pro detekci k칩d콢!
    raw_tokens = re.findall(r'\b\w+\b', query_text)

    scored_embeddings = []
    for item in embeddings:
        # 1. Z치kladn칤 sk칩re (S칠mantika)
        score = cosine_similarity(query_embedding, item["vector"])

        # 2. Smart Keyword Boost
        item_title = item["title"]  # P콢vodn칤 title s velk칳mi p칤smeny

        boost = 0.0
        for token in raw_tokens:
            # Aplikujeme boost JENOM pokud to vypad치 jako k칩d p콏edm캩tu
            if is_subject_code(token):
                # Hled치me p콏esnou shodu k칩du v titulku (case-insensitive, ale boundary-sensitive)
                # \bTOKEN\b zajist칤, 쬰 ALG nenajde v "Algebra", ale najde v "(ALG)"
                if re.search(r'\b' + re.escape(token) + r'\b', item_title, re.IGNORECASE):
                    # Je to k칩d a je v nadpisu! Boost!
                    print(f"游 Boostuji: {item['title']} kv콢li k칩du '{token}'")
                    boost += 0.5  # Masivn칤 boost

        final_score = score + boost
        scored_embeddings.append((final_score, item))

    scored_embeddings.sort(key=lambda x: x[0], reverse=True)
    return [item for score, item in scored_embeddings[:k] if score > 0.2]


def rewrite_query_for_search(user_query):
    """LLM p콏epis dotazu."""
    system_prompt = """
    Jsi expertn칤 AI pro optimalizaci vyhled치vac칤ch dotaz콢 v univerzitn칤 datab치zi (RAG).

    Pravidla:
    - Pokud dotaz obsahuje zkratku (nap콏. OA1, ZPRO), ZACHOVEJ JI v p콏esn칠m zn캩n칤!
    - Pokud je dotaz obecn칳 ("kdy je z치pis"), roz코i콏 ho o kl칤캜ov치 slova ("harmonogram", "term칤n").
    - Odstra켿 balast.
    """

    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    data = {
        "model": "gpt-4o",
        "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_query}],
        "temperature": 0
    }

    try:
        response = requests.post(LLM_API_URL, headers=headers, json=data)
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"].strip()
    except Exception:
        pass
    return user_query


def get_response_from_llm(context_list, query):
    context_text = ""
    for idx, item in enumerate(context_list):
        source_info = item.get('source', 'Nezn치m칳 soubor')
        title_info = item.get('title', 'Bez n치zvu')
        context_text += f"\n--- ZDROJ {idx + 1}: {title_info} (Soubor: {source_info}) ---\n"
        context_text += item['text'] + "\n"

    system_prompt = """
    Jsi n치pomocn칳 AI asistent 'Sofim' pro Studijn칤 odd캩len칤 FIM UHK. 
    Odpov칤dej na ot치zky student콢 POUZE na z치klad캩 poskytnut칠ho kontextu.
    Pokud odpov캩캞 v kontextu nen칤, slu코n캩 콏ekni, 쬰 tuto informaci nem치코.
    """

    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    data = {
        "model": "gpt-4o",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Kontext:\n{context_text}\n\nDotaz studenta: {query}"}
        ],
        "temperature": 0.3
    }

    try:
        response = requests.post(LLM_API_URL, headers=headers, json=data)
        if response.status_code == 200: return response.json()["choices"][0]["message"]["content"].strip()
    except Exception:
        return f"Chyba API (Status {response.status_code}): {response.text}"
    return f"Chyba API (Status {response.status_code}): {response.text}"


# --- Routes ---

@app.route("/api/chat", methods=["POST"])
def api_chat():
    data = request.get_json()
    user_query = data.get("query")
    if not user_query: return jsonify({"error": "Empty query"}), 400

    search_query = rewrite_query_for_search(user_query)
    query_embedding = get_query_embedding(search_query)
    embeddings = load_embeddings_from_db()

    # Hled치n칤 s chytr칳m boostem (p콏ed치v치me p콢vodn칤 dotaz pro detekci k칩d콢)
    best_matches = find_top_k_matches(query_embedding, embeddings, user_query, k=3)

    response_sources = []
    response_text = ""

    if best_matches:
        response_text = get_response_from_llm(best_matches, user_query)
        seen = set()
        for match in best_matches:
            src = match.get('title') or match.get('source', 'Zdroj')
            if src not in seen:
                response_sources.append(src)
                seen.add(src)
    else:
        response_text = "Bohu쬰l k tomuto dotazu nem치m v datab치zi 쮂멳n칠 informace."

    return jsonify({"response": response_text, "sources": response_sources})


@app.route("/", methods=["GET", "POST"])
def home():
    return render_template("index.html")


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001, debug=True)