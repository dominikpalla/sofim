import numpy as np
import json
from flask import Flask, request, render_template, jsonify
import requests
from database import load_embeddings_from_db
from config import OPENAI_API_KEY, EMBEDDING_MODEL, OPENAI_EMBEDDING_URL, LLM_API_URL

app = Flask(__name__)


# --- Pomocn√© funkce ---

def get_query_embedding(query):
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    data = {"input": query, "model": EMBEDDING_MODEL}
    response = requests.post(OPENAI_EMBEDDING_URL, headers=headers, json=data)
    if response.status_code == 200:
        return np.array(response.json()["data"][0]["embedding"])
    return None


def cosine_similarity(v1, v2):
    norm_v1 = np.linalg.norm(v1)
    norm_v2 = np.linalg.norm(v2)
    if norm_v1 == 0 or norm_v2 == 0:
        return 0
    return np.dot(v1, v2) / (norm_v1 * norm_v2)


def find_top_k_matches(query_embedding, embeddings, k=3):
    """Najde K nejlep≈°√≠ch shod v datab√°zi."""
    if not embeddings:
        return []

    scored_embeddings = []
    for item in embeddings:
        score = cosine_similarity(query_embedding, item["vector"])
        scored_embeddings.append((score, item))

    # Se≈ôadit sestupnƒõ podle sk√≥re
    scored_embeddings.sort(key=lambda x: x[0], reverse=True)

    # Vr√°tit top K
    return [item for score, item in scored_embeddings[:k] if score > 0.2]


def rewrite_query_for_search(user_query):
    """
    P≈ôep√≠≈°e dotaz u≈æivatele tak, aby byl optimalizovan√Ω pro s√©mantick√© vyhled√°v√°n√≠.
    Dopln√≠ kontext, kl√≠ƒçov√° slova a synonyma.
    """
    print(f"üîÑ P≈Øvodn√≠ dotaz: {user_query}")

    system_prompt = """
    Jsi expertn√≠ AI pro optimalizaci vyhled√°vac√≠ch dotaz≈Ø v univerzitn√≠ datab√°zi (RAG).
    Tv√Ωm √∫kolem je p≈ôeformulovat dotaz studenta tak, aby byl co nejlep≈°√≠ pro s√©mantick√© vyhled√°v√°n√≠ (embeddingy).

    Zdroje obsahuj√≠:
    1. Informace o p≈ôedmƒõtech (k√≥dy, n√°zvy, garanti, kredity, anotace).
    2. Smƒõrnice a vyhl√°≈°ky (term√≠ny, pravidla, omluvy).

    Pravidla:
    - Pokud dotaz zmi≈àuje n√°zev p≈ôedmƒõtu, p≈ôidej slova jako "p≈ôedmƒõt", "sylabus", "garant", "kredity".
    - Pokud je dotaz na smƒõrnici, p≈ôidej form√°ln√≠ term√≠ny (nap≈ô. "omluvenka" -> "omluva z v√Ωuky", "l√©ka≈ôsk√© potvrzen√≠").
    - Odstra≈à balast ("ahoj", "pros√≠m tƒõ", "chtƒõl bych vƒõdƒõt").
    - V√Ωstup mus√≠ b√Ωt POUZE vylep≈°en√Ω vyhled√°vac√≠ dotaz, nic jin√©ho.
    """

    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    data = {
        "model": "gpt-4o",  # Nebo gpt-4o-mini pro rychlost
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Dotaz: {user_query}"}
        ],
        "temperature": 0  # Chceme deterministick√Ω v√Ωstup
    }

    try:
        response = requests.post(LLM_API_URL, headers=headers, json=data)
        if response.status_code == 200:
            optimized_query = response.json()["choices"][0]["message"]["content"].strip()
            print(f"‚ú® Optimalizovan√Ω dotaz: {optimized_query}")
            return optimized_query
    except Exception as e:
        print(f"‚ö†Ô∏è Chyba p≈ôi optimalizaci dotazu: {e}")

    return user_query  # Fallback na p≈Øvodn√≠ dotaz


def get_response_from_llm(context_list, query):
    context_text = ""
    for idx, item in enumerate(context_list):
        source_info = item.get('source', 'Nezn√°m√Ω soubor')
        title_info = item.get('title', 'Bez n√°zvu')
        context_text += f"\n--- ZDROJ {idx + 1}: {title_info} (Soubor: {source_info}) ---\n"
        context_text += item['text'] + "\n"

    system_prompt = """
    Jsi n√°pomocn√Ω AI asistent 'Sofim' pro Studijn√≠ oddƒõlen√≠ FIM UHK. 
    Odpov√≠dej na ot√°zky student≈Ø POUZE na z√°kladƒõ poskytnut√©ho kontextu.
    Pokud odpovƒõƒè v kontextu nen√≠, slu≈°nƒõ ≈ôekni, ≈æe tuto informaci nem√°≈°.
    Odpov√≠dej struƒçnƒõ, jasnƒõ a p≈ô√°telsky.
    """

    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    data = {
        "model": "gpt-4o",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Kontext:\n{context_text}\n\nDotaz studenta: {query}"}
        ],
        "temperature": 0.3
    }

    try:
        response = requests.post(LLM_API_URL, headers=headers, json=data)
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"].strip()
        else:
            return "Omlouv√°m se, chyba API."
    except Exception:
        return "Omlouv√°m se, chyba komunikace."


# --- Routes ---

@app.route("/api/chat", methods=["POST"])
def api_chat():
    data = request.get_json()
    user_query = data.get("query")

    if not user_query:
        return jsonify({"error": "Empty query"}), 400

    # 1. KROK: P≈ôeformulov√°n√≠ dotazu pro lep≈°√≠ vyhled√°v√°n√≠
    search_query = rewrite_query_for_search(user_query)

    # 2. KROK: Hled√°n√≠ v DB pomoc√≠ VYLEP≈†EN√âHO dotazu
    query_embedding = get_query_embedding(search_query)
    embeddings = load_embeddings_from_db()
    best_matches = find_top_k_matches(query_embedding, embeddings, k=3)

    response_sources = []
    response_text = ""

    if best_matches:
        # 3. KROK: Odpovƒõƒè generujeme na p≈Øvodn√≠ dotaz u≈æivatele (aby to znƒõlo p≈ôirozenƒõ),
        # ale s kontextem nalezen√Ωm pomoc√≠ vylep≈°en√©ho dotazu.
        response_text = get_response_from_llm(best_matches, user_query)

        seen_sources = set()
        for match in best_matches:
            source_to_show = match.get('title')
            if not source_to_show:
                source_to_show = match.get('source', 'Nezn√°m√Ω zdroj')

            if source_to_show and source_to_show not in seen_sources:
                response_sources.append(source_to_show)
                seen_sources.add(source_to_show)
    else:
        response_text = "Bohu≈æel k tomuto dotazu nem√°m v datab√°zi ≈æ√°dn√© informace. Zkuste se zeptat jinak nebo kontaktujte studijn√≠ oddƒõlen√≠."

    return jsonify({"response": response_text, "sources": response_sources})


@app.route("/", methods=["GET", "POST"])
def home():
    return render_template("index.html")


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001, debug=True)