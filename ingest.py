import os
import json
import requests
import numpy as np
import pandas as pd
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
import io
import docx
from pypdf import PdfReader
from config import OPENAI_API_KEY, GOOGLE_DRIVE_FOLDER_ID, GOOGLE_CREDENTIALS_FILE, EMBEDDING_MODEL, \
    OPENAI_EMBEDDING_URL
# Importujeme funkce pro st√≠novou tabulku (Zero Downtime)
from database import init_next_table, insert_into_next_table, swap_tables_atomic


# --- 1. P≈ôipojen√≠ ke Google Disku ---
def get_drive_service():
    if not os.path.exists(GOOGLE_CREDENTIALS_FILE):
        print(f"‚ùå Chyba: Soubor {GOOGLE_CREDENTIALS_FILE} nenalezen.")
        return None
    creds = service_account.Credentials.from_service_account_file(
        GOOGLE_CREDENTIALS_FILE, scopes=['https://www.googleapis.com/auth/drive.readonly'])
    return build('drive', 'v3', credentials=creds)


def read_csv_smart(fh):
    """Naƒçte CSV s d≈Ørazem na zachov√°n√≠ v≈°ech dat, porad√≠ si s k√≥dov√°n√≠m i oddƒõlovaƒçi."""
    encodings = ['utf-8', 'cp1250', 'latin1']

    for encoding in encodings:
        fh.seek(0)
        try:
            # P≈ôeƒçteme CSV, automatick√° detekce oddƒõlovaƒçe (sep=None) vy≈æaduje engine='python'
            df = pd.read_csv(fh, sep=None, engine='python', encoding=encoding, on_bad_lines='skip')

            # --- Validace hlaviƒçky ---
            # Hled√°me kl√≠ƒçov√° slova z tv√©ho souboru (podle tv√©ho uploadu)
            keywords = ['zkratka', 'zkr_predm', 'nazev_cz', 'kredity', 'anotace_cz']

            # Pokud v souƒçasn√Ωch sloupc√≠ch nen√≠ nic z kl√≠ƒçov√Ωch slov, zkus√≠me naj√≠t hlaviƒçku n√≠≈æe
            # (Nƒõkdy exporty zaƒç√≠naj√≠ pr√°zdn√Ωmi ≈ô√°dky nebo metadaty)
            col_str = str(list(df.columns)).lower()
            if not any(k in col_str for k in keywords):
                print(f"   üïµÔ∏è‚Äç‚ôÄÔ∏è Hled√°m hlaviƒçku tabulky v {encoding}...")
                fh.seek(0)
                # Naƒçteme kousek bez hlaviƒçky
                df_raw = pd.read_csv(fh, sep=None, engine='python', encoding=encoding, header=None, on_bad_lines='skip',
                                     nrows=15)

                header_index = -1
                for i in range(len(df_raw)):
                    row_str = str(df_raw.iloc[i].values).lower()
                    if any(k in row_str for k in keywords):
                        header_index = i
                        break

                if header_index != -1:
                    fh.seek(0)
                    df = pd.read_csv(fh, sep=None, engine='python', encoding=encoding, header=header_index,
                                     on_bad_lines='skip')
                    print(f"   ‚úÖ Hlaviƒçka nalezena na ≈ô√°dku {header_index}.")

            # Vyƒçi≈°tƒõn√≠
            df = df.dropna(how='all')  # Sma≈æe pr√°zdn√© ≈ô√°dky
            df = df.fillna("")  # NaN -> ""

            # Normalizace n√°zv≈Ø sloupc≈Ø (odstranƒõn√≠ mezer na zaƒç√°tku/konci n√°zvu sloupce)
            df.columns = [str(c).strip() for c in df.columns]

            return df

        except Exception:
            continue

    return None


def process_file_content(service, file_item):
    print(f"  üìÑ Stahuji soubor: {file_item['name']}...")

    supported_types = [
        'application/pdf',
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
        'text/csv',
        'application/vnd.ms-excel'
    ]

    # Rychl√° kontrola koncovky a MIME typu
    if not (file_item['mimeType'] in supported_types or file_item['name'].endswith(('.pdf', '.docx', '.csv'))):
        return None

    try:
        request = service.files().get_media(fileId=file_item['id'])
        fh = io.BytesIO()
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while done is False:
            status, done = downloader.next_chunk()

        fh.seek(0)

        # --- CSV ---
        if file_item['name'].endswith('.csv'):
            df = read_csv_smart(fh)
            if df is not None:
                return {"filename": file_item['name'], "type": "csv", "data": df}
            else:
                print(f"   ‚ùå Nepoda≈ôilo se p≈ôeƒç√≠st CSV {file_item['name']} (ani utf-8, ani cp1250).")
                return None

        # --- DOCX ---
        text = ""
        if file_item['name'].endswith('.docx'):
            try:
                doc = docx.Document(fh)
                text = "\n".join([p.text for p in doc.paragraphs if p.text.strip() != ""])
            except Exception as e:
                print(f"   ‚ùå Chyba ƒçten√≠ DOCX {file_item['name']}: {e}")

        # --- PDF ---
        elif file_item['name'].endswith('.pdf'):
            try:
                reader = PdfReader(fh)
                count = 0
                for page in reader.pages:
                    extracted = page.extract_text()
                    if extracted:
                        text += extracted + "\n"
                        count += 1

                # Detekce "pr√°zdn√©ho" PDF (sken)
                if len(text.strip()) == 0 and count > 0:
                    print(f"   ‚ö†Ô∏è PDF {file_item['name']} m√° str√°nky, ale ≈æ√°dn√Ω text. Asi sken?")
            except Exception as e:
                print(f"   ‚ùå Chyba ƒçten√≠ PDF {file_item['name']}: {e}")

        # Validace textu (pro PDF/DOCX)
        if text:
            text_len = len(text.strip())
            if text_len < 10:
                print(f"   ‚ö†Ô∏è VAROV√ÅN√ç: Soubor {file_item['name']} obsahuje jen {text_len} znak≈Ø! (Ignoruji)")
                return None

            return {"filename": file_item['name'], "type": "text", "text": text}

    except Exception as e:
        print(f"‚ö†Ô∏è Chyba p≈ôi stahov√°n√≠ {file_item['name']}: {e}")

    return None


def get_files_recursive(service, folder_id):
    results_list = []
    page_token = None

    while True:
        try:
            response = service.files().list(
                q=f"'{folder_id}' in parents and trashed = false",
                fields="nextPageToken, files(id, name, mimeType)",
                pageToken=page_token
            ).execute()
        except Exception as e:
            print(f"‚ö†Ô∏è Chyba p≈ôi listov√°n√≠ slo≈æky: {e}")
            break

        items = response.get('files', [])

        for item in items:
            if item['mimeType'] == 'application/vnd.google-apps.folder':
                print(f"üìÇ Vstupuji do podslo≈æky: {item['name']}")
                results_list.extend(get_files_recursive(service, item['id']))
            else:
                processed_file = process_file_content(service, item)
                if processed_file:
                    results_list.append(processed_file)

        page_token = response.get('nextPageToken')
        if not page_token:
            break

    return results_list


# --- 2. Chunking funkce ---

# A) S√©mantick√© ≈ôez√°n√≠ pro dokumenty (PDF/DOCX)
def semantic_chunking(text, filename):
    print(f"üß† S√©mantick√© ≈ôez√°n√≠ souboru: {filename}...")

    if not text or len(text.strip()) < 10:
        return []

    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    shortened_text = text[:12000]

    prompt = f"""
    Jsi expertn√≠ analytik. Rozdƒõl text na logick√© celky (chunky).
    Vstupn√≠ soubor: {filename}
    Pravidla:
    1. V√Ωstup MUS√ç b√Ωt validn√≠ JSON.
    2. Form√°t: {{"chunks": [ {{"title": "...", "content": "..."}} ]}}
    Text k anal√Ωze:
    {shortened_text}
    """

    data = {
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": prompt}],
        "response_format": {"type": "json_object"}
    }

    try:
        response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data)

        if response.status_code != 200:
            print(f"‚ö†Ô∏è API Error {response.status_code}: {response.text}")
            raise Exception("API call failed")

        result = response.json()
        content = result["choices"][0]["message"]["content"]
        json_content = json.loads(content)

        if "chunks" in json_content: return json_content["chunks"]
        if "items" in json_content: return json_content["items"]
        if isinstance(json_content, list): return json_content

    except Exception as e:
        print(f"‚ö†Ô∏è Chyba AI chunkingu u {filename}: {e}. Pou≈æ√≠v√°m Fallback.")

    return [{"title": filename, "content": text}]


# B) ≈ò√°dkov√© ≈ôez√°n√≠ pro tabulky (CSV) - NASTAVENO PRO TV≈ÆJ EXPORT
def csv_row_chunking(df, filename):
    print(f"üìä Zpracov√°v√°m tabulku p≈ôedmƒõt≈Ø: {filename} ({len(df)} ≈ô√°dk≈Ø)...")
    chunks = []

    for index, row in df.iterrows():
        row_dict = row.to_dict()

        # 1. Identifikace p≈ôedmƒõtu (N√°zev + K√≥d)
        # Hled√°me konkr√©tn√≠ sloupce z tv√©ho souboru
        nazev = row_dict.get('NAZEV_CZ', '')
        if not nazev:
            # Fallback
            nazev = row_dict.get('NAZEV_AN', 'Nezn√°m√Ω p≈ôedmƒõt')

        kod = row_dict.get('ZKR_PREDM', '')
        if not kod:
            # Fallback pro jin√© n√°zvy sloupc≈Ø
            for k, v in row_dict.items():
                if 'zkr' in str(k).lower() and not kod: kod = str(v)

        # Pokud nem√°me ani n√°zev, ani k√≥d, ≈ô√°dek p≈ôeskoƒç√≠me (asi pr√°zdn√Ω)
        if nazev == 'Nezn√°m√Ω p≈ôedmƒõt' and not kod:
            continue

        title = f"P≈ôedmƒõt: {nazev} ({kod})".strip()

        # 2. Sestaven√≠ obsahu (Form√°tovan√Ω text)
        content_lines = [f"--- Detail p≈ôedmƒõtu: {title} ---"]

        # Definujeme pole, kter√° chceme vyt√°hnout P≈òEDNOSTNƒö a jejich ƒçesk√© popisky
        priority_fields = {
            'NAZEV_AN': 'Anglick√Ω n√°zev',
            'GARANTI': 'Garanti',
            'VYUCUJICI': 'Vyuƒçuj√≠c√≠',
            'KREDITY': 'Kredity',
            'ROK_VARIANTY': 'Rok varianty',
            'ANOTACE_CZ': 'Anotace',
            'CIL_CZ': 'C√≠le p≈ôedmƒõtu',
            'OSNOVA_CZ': 'Osnova',
            'LITERATURA': 'Literatura',
            'POZADAVKY_CZ': 'Po≈æadavky na studenta',
            'METODY_VYUKY_CZ': 'Metody v√Ωuky',
            'URL': 'Odkaz'
        }

        # Nejprve vyp√≠≈°eme prioritn√≠ pole (pokud v ≈ô√°dku jsou a nejsou pr√°zdn√°)
        for key, label in priority_fields.items():
            if key in row_dict:
                val = str(row_dict[key]).strip()
                if val and val.lower() != 'nan':
                    content_lines.append(f"{label}: {val}")

        # Potom projedeme zbytek sloupc≈Ø, abychom o nic nep≈ôi≈°li
        # (Vynech√°me ty, co u≈æ jsme vypsali, a technick√© sloupce)
        ignored_cols = ['FAKULTA', 'PRAC_ZKR', 'STAV_AKREDITACE', 'ZKR_PREDM', 'NAZEV_CZ']

        for k, v in row_dict.items():
            k_str = str(k)
            # Pokud u≈æ jsme to vypsali nebo to chceme ignorovat -> p≈ôeskoƒçit
            if k_str in priority_fields or k_str in ignored_cols:
                continue
            # Pokud je to "Unnamed" nebo pr√°zdn√© -> p≈ôeskoƒçit
            if "unnamed" in k_str.lower():
                continue

            val = str(v).strip()
            if val and val.lower() != 'nan':
                # Hezk√© form√°tov√°n√≠ n√°zvu sloupce (nap≈ô. TYP_ZK -> Typ Zk)
                nice_k = k_str.replace('_', ' ').title()
                content_lines.append(f"{nice_k}: {val}")

        content = "\n".join(content_lines)

        chunks.append({
            "title": title,
            "content": content
        })

    return chunks


# --- 3. Embedding ---
def get_embedding(text):
    if not text or not text.strip():
        return None

    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    data = {"input": text, "model": EMBEDDING_MODEL}

    try:
        response = requests.post(OPENAI_EMBEDDING_URL, headers=headers, json=data)
        if response.status_code == 200:
            return np.array(response.json()["data"][0]["embedding"])
        else:
            print(f"‚ö†Ô∏è Chyba Embeddings API: {response.text}")
    except Exception as e:
        print(f"‚ö†Ô∏è Chyba p≈ôi embeddingu: {e}")

    return None


# --- HLAVN√ç LOOP (ZERO DOWNTIME) ---
if __name__ == "__main__":
    print("üöÄ Startuji Zero-Downtime Indexaci...")

    # 1. P≈ôiprav√≠me st√≠novou tabulku (funkce sama sma≈æe starou a vytvo≈ô√≠ novou)
    init_next_table()
    print("üëª St√≠nov√° tabulka (embeddings_next) p≈ôipravena.")

    service = get_drive_service()

    if service:
        files_data = get_files_recursive(service, GOOGLE_DRIVE_FOLDER_ID)

        print(f"‚úÖ Nalezeno a sta≈æeno celkem {len(files_data)} soubor≈Ø.")

        if files_data:
            success_count = 0

            for i, file_item in enumerate(files_data):
                chunks = []

                # Rozhodov√°n√≠ typu
                if file_item.get("type") == "csv":
                    # CSV -> ≈ò√°dkov√Ω chunking s prioritn√≠mi poli
                    chunks = csv_row_chunking(file_item['data'], file_item['filename'])
                else:
                    # Text/PDF -> AI chunking
                    print(f"[{i + 1}/{len(files_data)}] AI Zpracov√°n√≠: {file_item['filename']}")
                    chunks = semantic_chunking(file_item['text'], file_item['filename'])

                if not chunks:
                    continue

                for chunk in chunks:
                    title = chunk.get("title", file_item['filename'])
                    text_content = chunk.get("content", "")

                    if text_content:
                        # Obohacen√Ω kontext pro lep≈°√≠ vyhled√°v√°n√≠
                        enriched_text_for_embedding = (
                            f"Zdrojov√Ω soubor: {file_item['filename']}\n"
                            f"T√©ma: {title}\n"
                            f"Obsah: {text_content}"
                        )

                        emb = get_embedding(enriched_text_for_embedding)

                        if emb is not None:
                            # 2. Vkl√°d√°me do ST√çNOV√â tabulky
                            insert_into_next_table(title, text_content, emb, file_item['filename'])

                            if file_item.get("type") != "csv":
                                print(f"   üíæ Ulo≈æeno: {title[:40]}...")

                if file_item.get("type") == "csv":
                    print(f"   ‚úÖ Ulo≈æeno {len(chunks)} z√°znam≈Ø z CSV tabulky.")

                if len(chunks) > 0:
                    success_count += 1

            # 3. Pokud probƒõhlo zpracov√°n√≠ √∫spƒõ≈°nƒõ, prohod√≠me tabulky
            if success_count > 0:
                print("üîÑ Prov√°d√≠m atomick√© prohozen√≠ tabulek (Swap)...")
                swap_tables_atomic()
                print("üéâ Hotovo! Nov√° data jsou LIVE. U≈æivatel√© nic nepoznali.")
            else:
                print("‚ö†Ô∏è Nebyla zpracov√°na ≈æ√°dn√° data, tabulky neprohazuji.")
        else:
            print("‚ö†Ô∏è ≈Ω√°dn√© relevantn√≠ soubory nenalezeny.")